m<- makeCacheMatrix( )
m$set( matrix( c(0, 2, 2, 0 ), 2, 2))
m$get()
cacheSolve( m )
cacheSolve( m )
makeCacheMatrix <- function(x = matrix()) {
im <- NULL
set <- function(y) {
## Reset values
x <<- y
im <<- NULL
}
get <- function() x
setInverseMatrix <- function(inverseMatrix) im <<- inverseMatrix  ## set the value into the global environment
getInverseMatrix <- function() im  ## pick up the value from the global environment
list(set = set, get = get,
setInverseMatrix = setInverseMatrix,
getInverseMatrix = getInverseMatrix)
}
## cacheSolve - This function takes the result of makeCacheMatrix as an argument and
## returns the inverse of the matrix made in makeCacheMatrix.
## It uses the makeCacheMatrix getInverseMatrix function to pull the inverse
## of the matrix from cache if it was already calculated.  Otherwise, it calculates
## the inverse of the matrix and stores the result in cache by using the
## setInverseMatrix function from makeCacheMatrix.
cacheSolve <- function(x, ...) {
im <- x$getInverseMatrix() ## see if the inverse is already available in cache
if(!is.null(im)) {
message("getting cached data")
return(im)  ## if it is available then just return it
}
## if it isn't available in cache the compute the inverse and set the result in cache
matrix <- x$get()
im <- solve(matrix)  ## compute the inverse
x$setInverseMatrix(im)
im
}
m<- makeCacheMatrix( )
m$set( matrix( c(0, 2, 2, 0 ), 2, 2))
m$get()
cacheSolve( m )
cacheSolve( m )
makeCacheMatrix <- function(x = matrix()) {
##This is an empty matrix
i <- matrix()
##Set the value of matrix.
set <- function(y) {
y <- matrix(y, nrow=2, ncol=2)
x <<- y
i <<- matrix()
}
##Get the value of matrix.
get <- function() x
setinverse <- function(x) {
i <<- solve(x)
}
##Get the value of inverse
getinverse <- function() i
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
##This function computes the inverse of the special "matrix" returned by makeCacheMatrix above with
##the requirements that the code checks if the inverse was already calculated or not.
cacheSolve <- function(x, ...) {
i <- x$getinverse()
##Case when the inverse was already calculated.
if(!is.null(i)) {
message("Getting cashed data")
return(i)
}
##Case when the inverse wasn't calculated. Calculation will be done.
data <- x$get()
i <- solve(data, ...)
x$setinverse(i)
i
}
m<- makeCacheMatrix( )
m$set( matrix( c(0, 2, 2, 0 ), 2, 2))
m$get()
cacheSolve( m )
m$set( c(0, 2, 2, 0 ))
m$get()
cacheSolve( m )
m$getInverse()
m$getinverse()
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
summaryRprof(fit)
summaryRprof(lm)
fit <- lm(y ~ x1 + x2)
Rprof()
summaryRprof()
summaryRprof(fit)
summaryRprof(fit)
set.seed(1)
rpois(5,2)
rpois(5,2)
rpois(5,2)
rpois(5,2)
?qpois
?ls
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript3.R")
submit()
submit()
submit()
library(XML)
library(xlsx)
fileUrl <- "http://www.w3schools.com/xml/simple/xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
install.packages(c("evaluate", "memoise", "swirl", "yaml"))
library(xlsx)
install.packages("rJava")
library(xlsx)
library(xlsx)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl, destfile="gas.xlsx")
g_data <- read.xlsx("gas.xlsx", sheetIndex=1, colIndex=7:15, rowIndex=18:23)
g_data <- read.xlsx("gas.xlsx", sheetIndex=1)
Sys.getenv("JAVA_HOME")
if (Sys.getenv("JAVA_HOME")!="")
Sys.setenv(JAVA_HOME="")
library(rJava)
g_data <- read.xlsx("gas.xlsx", sheetIndex=1, colIndex=7:15, rowIndex=18:23)
g_data <- read.xlsx("gas.xlsx", sheetIndex=1)
install.packages("RMySQL", type = "source")
library(RMySQL)
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ7hl=en")
htmlCode=readLines(con)
close(con)
htmlCode
library(httr)
install.packages("httr")
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "0e4b2fad8f0945a986cdf03c8697d4755c14c57c")
?oauth_app
myapp <- oauth_app("github", key="Ms-Bubbles", secret= NULL)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(github, my app)
github_token <- oauth2.0_token("github", my app)
github_token <- oauth2.0_token(github, myapp)
?oauth2.0_token
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github <- oauth_endpoints("https://api.github.com/users/jtleek/repos")
github <- oauth_endpoints("https://github.com/")
github <- oauth_endpoints("github")
github_token <- oauth2.0_token(github, myapp)
myapp <- oauth_app("github", key="Ms-Bubbles", secret= "elimbic145")
github <- oauth_endpoints("github")
github_token <- oauth2.0_token(github, myapp)
myapp <- oauth_app("github", key="Ms-Bubbles", secret= "NULL")
github_token <- oauth2.0_token(github, my app)
githubtoken <- oauth2.0_token(github, my app)
githubtoken <- oauth2.0_token(github, myapp)
gtoken <- config(token = github_token)
github_token <- oauth2.0_token(github, myapp)
gtoken <- config(token = github_token)
library(httr)
?oauth_endpoints
?oauth_app
github <- oauth_endpoints("github")
myapp <- oauth_app("github",key="893ee3afb4009687d9df", secret = NULL)
library(hhtpuv)
install.packages("httpuv")
library(hhtpuv)
library(httpuv)
library(httpuv)
library(httpuv)
install.packages("httpuv")
library(httpuv)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
json1 = content(req)
json2 = jsonlite::fromJSON(toJSON(json1))
library("jsonlite")
json2 = jsonlite::fromJSON(toJSON(json1))
json2
req
myapp <- oauth_app("github",key="893ee3afb4009687d9df", secret = "0f63c5deed39553ccb13ccac0fbb672f7681e416")
req
jsonData <- fromJSON("https://api.github.com/users/jtleek/repos")
names(jsonData)
jsonData
jsonData[1, 1:4]
jsonData[2, 1:4]
head(jsonData)
summary(jsonData)
jsonData$created_at
jsonData[1, 1:5]
jsonData[5, created_at]
jsonData[5, ]
jsonData$"name"=="datasharing"
dim(jsonData)
class(jsonData)
jsonData["datasharing", ]
names(jsonData)
jsonData["name": "datasharing","created_at"]
jsonData["datasharing","created_at"]
jsonData[datasharing,created_at]
jsonData[datasharing,"created_at"]
jsonData[name == "datasharing",]
jsonData[== "datasharing",]
jsonData["datasharing",]
jsonData$name == "datasharing"
jsonData$name ='datasharing'
ds <- jsonData$name ='datasharing'
ds <- jsonData$name
ds
ds$created_at
jsonData
head(jsonData)
install.packages("sqldf")
setwd("./UCI HAR Dataset")
##preparing descriptive labels to column names
header <- read.table("./features.txt")
header <- as.factor(header$V2)
testData <- read.table("./test/X_test.txt")
##assigning descriptive labels to column names
colnames(testData) <- header
testLabels <- read.table("./test/y_test.txt")
colnames(testLabels)<- c("Labels")
testSubjects <- read.table("./test/subject_test.txt")
colnames(testSubjects)<- c("SubjectIDs")
test <- cbind(testSubjects, testLabels, testData)
trainData <- read.table("./train/X_train.txt")
##assigning descriptive labels to column names
colnames(trainData) <- header
trainLabels <- read.table("./train/y_train.txt")
colnames(trainLabels)<- c("Labels")
trainSubjects <- read.table("./train/subject_train.txt")
colnames(trainSubjects)<- c("SubjectIDs")
train <- cbind(trainSubjects, trainLabels, trainData)
##merge the two data sets
bindData <- rbind(test, train)
labels <- names(bindData)
sel_mean <- grep("-mean()", labels, fixed = TRUE)
sel_std <- grep("-std()", labels, fixed = TRUE)
means <- bindData[,sel_mean]
stds <- bindData[,sel_std]
cleanData <- cbind(SubjectIDs = bindData$SubjectIDs, Labels = bindData$Labels, means, stds)
##assigning descriptive activity names to variables
cleanData$Labels[cleanData$Labels =="1"] <-"WALKING"
cleanData$Labels[cleanData$Labels =="2"] <-"WALKING_UPSTAIRS"
cleanData$Labels[cleanData$Labels =="3"] <-"WALKING_DOWNSTAIRS"
cleanData$Labels[cleanData$Labels =="4"] <-"SITTING"
cleanData$Labels[cleanData$Labels =="5"] <-"STANDING"
cleanData$Labels[cleanData$Labels =="6"] <-"LAYING"
##Point 5: Creating independent tidy data set with the average of each variable for each activity and each subject
tidyData <- aggregate(cleanData[,3:ncol(cleanData)], list(SubjectIDs=cleanData$SubjectIDs, ActivityLabels=cleanData$Labels), mean)
##Sorting the data based on the subject ids
tidyData <- tidyData[order(tidyData$SubjectIDs, decreasing=FALSE),]
tidyData$SubjectIDs <- as.factor(tidyData$SubjectIDs)
##Creating an output file with the tidy data
write.table(tidyData, file="./TidyData.txt", sep="\t", row.names=FALSE)
setwd("./RWorking Directory/UCI HAR Dataset")
##preparing descriptive labels to column names
header <- read.table("./features.txt")
header <- as.factor(header$V2)
testData <- read.table("./test/X_test.txt")
##assigning descriptive labels to column names
colnames(testData) <- header
testLabels <- read.table("./test/y_test.txt")
colnames(testLabels)<- c("Labels")
testSubjects <- read.table("./test/subject_test.txt")
colnames(testSubjects)<- c("SubjectIDs")
test <- cbind(testSubjects, testLabels, testData)
trainData <- read.table("./train/X_train.txt")
##assigning descriptive labels to column names
colnames(trainData) <- header
trainLabels <- read.table("./train/y_train.txt")
colnames(trainLabels)<- c("Labels")
trainSubjects <- read.table("./train/subject_train.txt")
colnames(trainSubjects)<- c("SubjectIDs")
train <- cbind(trainSubjects, trainLabels, trainData)
##merge the two data sets
bindData <- rbind(test, train)
labels <- names(bindData)
sel_mean <- grep("-mean()", labels, fixed = TRUE)
sel_std <- grep("-std()", labels, fixed = TRUE)
means <- bindData[,sel_mean]
stds <- bindData[,sel_std]
cleanData <- cbind(SubjectIDs = bindData$SubjectIDs, Labels = bindData$Labels, means, stds)
##assigning descriptive activity names to variables
cleanData$Labels[cleanData$Labels =="1"] <-"WALKING"
cleanData$Labels[cleanData$Labels =="2"] <-"WALKING_UPSTAIRS"
cleanData$Labels[cleanData$Labels =="3"] <-"WALKING_DOWNSTAIRS"
cleanData$Labels[cleanData$Labels =="4"] <-"SITTING"
cleanData$Labels[cleanData$Labels =="5"] <-"STANDING"
cleanData$Labels[cleanData$Labels =="6"] <-"LAYING"
##Point 5: Creating independent tidy data set with the average of each variable for each activity and each subject
tidyData <- aggregate(cleanData[,3:ncol(cleanData)], list(SubjectIDs=cleanData$SubjectIDs, ActivityLabels=cleanData$Labels), mean)
##Sorting the data based on the subject ids
tidyData <- tidyData[order(tidyData$SubjectIDs, decreasing=FALSE),]
tidyData$SubjectIDs <- as.factor(tidyData$SubjectIDs)
##Creating an output file with the tidy data
write.table(tidyData, file="./TidyData.txt", sep="\t", row.names=FALSE)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
y <- x*w
y
mean(y)
mean(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
beta1 <- cor(y, x)*sd(y)/sd(x)
beta1
coef(lm(y~x))
data(mtcars)
summary(mtcars)
coef(lm(mtcars$mpg~mtcars$weight))
coef(lm(mtcars$mpg~mtcars$wt))
1.5*0.4
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
xn <- (x - mean(x)/sd(x))
xn
xn[2]
xn[1]
xn <- (x - mean(x))/sd(x)
xn[1]
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
coef(lm(y~x))
xn <- (x - mean(x))/sd(x)
yn <- (y - mean(y))/sd(y)
coef(lm(y~x))
coef(lm(yn~xn))
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
mean(x)
xw <- x*w
xw
mean(xw)
mean <- xw/w
mean
sum(xw)
sum(xw)/sum(w)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
beta1 <- sum(y*x)/sum(x^2)
beta1
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
coef(lm(y~x))
mean(x)
one <- sample(1:10, replace = TRUE)
two <- sample(1:10, replace = FALSE)
result <- rbind(one, two)
results <- as.matrix(result)
results
result
testData <- read.csv("pml-testing.csv")
trainData <- read.csv("pml-training.csv")
library(caret)
library(randomForest)
##should be ok to remove the time stamps for test as well
##ts <- grep("*.timestamp.*",colnames(trainData2), value=TRUE )
testData2 <- testData[,-c(3:5)]
trainData2 <- trainData[,-c(3:5)]
trainData2 <- trainData2[,colSums(is.na(trainData2)) < 0.8*nrow(trainData2)]
drop <- testData2[,colSums(is.na(testData2)) >= 0.8*nrow(testData2)]
trainData2 <- trainData2[, !colnames(trainData2) %in% colnames(drop)]
##Spending Data
set.seed(1210)
inTrain <- createDataPartition(trainData2$classe, p = 0.7, list = FALSE)
train <- trainData2[inTrain,]
test <- trainData2[-inTrain,]
setwd("D:/RWorking Directory/MachineLearning/MachineLearning/CourseProject")
testData <- read.csv("pml-testing.csv")
trainData <- read.csv("pml-training.csv")
library(caret)
library(randomForest)
##should be ok to remove the time stamps for test as well
##ts <- grep("*.timestamp.*",colnames(trainData2), value=TRUE )
testData2 <- testData[,-c(3:5)]
trainData2 <- trainData[,-c(3:5)]
trainData2 <- trainData2[,colSums(is.na(trainData2)) < 0.8*nrow(trainData2)]
drop <- testData2[,colSums(is.na(testData2)) >= 0.8*nrow(testData2)]
trainData2 <- trainData2[, !colnames(trainData2) %in% colnames(drop)]
##Spending Data
set.seed(1210)
inTrain <- createDataPartition(trainData2$classe, p = 0.7, list = FALSE)
train <- trainData2[inTrain,]
test <- trainData2[-inTrain,]
fitModel <- randomForest(classe ~ ., data=train,importance=TRUE, ntree=500, mdim2nd=20 , imp=1)
fitModel
vip <- varImp(fitModel)
vip
?varImp
myControl <- trainControl(method="cv",number=5,repeats=2,returnResamp="none")
fitModel2 <- train(classe ~ ., data=train, method="rf", trControl=myControl)
myControl <- trainControl(method="cv",number=10,repeats=2,returnResamp="none")
fitModel2 <- train(classe ~ ., data=train, method="rf", trControl=myControl)
testData2 <- testData[,-c(1:7)]
trainData2 <- trainData[,-c(1:7)]
trainData2 <- trainData2[,colSums(is.na(trainData2)) < 0.8*nrow(trainData2)]
drop <- testData2[,colSums(is.na(testData2)) >= 0.8*nrow(testData2)]
trainData2 <- trainData2[, !colnames(trainData2) %in% colnames(drop)]
##Spending Data
set.seed(1210)
inTrain <- createDataPartition(trainData2$classe, p = 0.7, list = FALSE)
train <- trainData2[inTrain,]
test <- trainData2[-inTrain,]
fitModel <- randomForest(classe ~ ., data=train,importance=TRUE, ntree=500, mdim2nd=20 , imp=1)
vip <- varImp(fitModel, scale=FALSE)
vip
plot(vip, top = 20)
?varImp
vip2 <- varImp(fitModel)
vip2
vip2 <- varImp(fitModel$classe)
vip2 <- varImp(fitModel$finalModel)
prediction <- predict(fitModel, train)
confusionMatrix(prediction, train$classe)
predictionTest <- predict(fitModel, test)
confusionMatrix(prediction, test$classe)
confusionMatrix(predictionTest, test$classe)
answers <- predict(fitModel, testData)
answers <- as.character(answers)
answers
a2 <- c("B" "A" "B" "A" "A" "E" "D" "B" "A" "A" "B" "C" "B" "A" "E" "E" "A" "B" "B" "B")
a2 <- c=("B" "A" "B" "A" "A" "E" "D" "B" "A" "A" "B" "C" "B" "A" "E" "E" "A" "B" "B" "B")
a2 <- c("B" "A" "B" "A" "A" "E" "D" "B" "A" "A" "B" "C" "B" "A" "E" "E" "A" "B" "B" "B")
a2 <- c("B", "A","B" ,"A", "A", "E" ,"D" ,"B" ,"A", "A", "B", "C" ,"B", "A" ,"E" ,"E" ,"A", "B", "B" ,"B")
d < rbind(answers, a2)
d <- rbind(answers, a2)
d
?randomForest
fitModel <- randomForest(classe ~ ., data=train,importance=TRUE, ntree=500, mdim2nd=20 , imp=2)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
setwd("D:/RWorking Directory/MachineLearning/MachineLearning/CourseProject/Answers")
pml_write_files(answers)
varImpPlot(fitModel)
sort(vip, A)
sort(vip, vip$A)
sort(vip, vip$A, decreasing+TRUE)
sort(vip, vip$A, decreasing=TRUE)
vip[order,]
vip[order(A),]
vip[order(classe),]
dim(vip)
colnames(vip)
fitModel$MeanDecreaseAccuracy
prediction$MeanDecreaseAccuracy
fitModel$importance
fitModel$importance$MeanDecreaseAccuracy
rownames(vip$importance)
rownames(vip)
rownames(fitModel$importance)
names(vip[order(vip, decreasing = TRUE)][1:20])
names(vip[order(vip, decreasing = TRUE),][1:20])
names(vip[,order(vip, decreasing = TRUE)][1:20])
names(vip[order(vip, A, decreasing = TRUE)][1:20])
names(vip[order(vip, , decreasing = TRUE)][1:20])
names(vip[order(vip, decreasing = TRUE)][1:20])
ImpMeasure<-data.frame(varImp(fitModel)$importance)
ImpMeasure$Vars<-row.names(ImpMeasure)
ImpMeasure[order(-ImpMeasure$Overall),][1:3,]
ImpMeasure[order(ImpMeasure$Overall),][1:3,]
View(ImpMeasure)
ImpMeasure<-data.frame(varImp(fitModel)$importance)
View(ImpMeasure)
ImpMeasure$Overall
top20 <- c("yaw_belt", "roll_belt", "pitch_belt", "magnet_dumbbell_z", "magnet_dumbbell_y",
"gyros_arm_y", "pitch_forearm", "gyros_forearm_z", "roll_arm", "accel_dumbbell_y", "gyros_dumbbell_z",
"magnet_belt_x", "magnet_forearm_z", "accel_dumbbell_z", "gyros_belt_z", "roll_dumbbell",
"yaw_forearm", "roll_forearm")
top20 <- c("yaw_belt", "roll_belt", "pitch_belt", "magnet_dumbbell_z", "magnet_dumbbell_y",
"gyros_arm_y", "pitch_forearm", "gyros_forearm_z", "roll_arm", "accel_dumbbell_y",         "gyros_dumbbell_z","magnet_belt_x", "magnet_forearm_z", "accel_dumbbell_z", "gyros_belt_z", "roll_dumbbell", "yaw_forearm", "roll_forearm", "magnet_forearm_y", "gyros_dumbbell_x")
train2 <- train[,-top20]
train2 <- train[,-c("yaw_belt", "roll_belt", "pitch_belt", "magnet_dumbbell_z", "magnet_dumbbell_y",
"gyros_arm_y", "pitch_forearm", "gyros_forearm_z", "roll_arm", "accel_dumbbell_y",         "gyros_dumbbell_z","magnet_belt_x", "magnet_forearm_z", "accel_dumbbell_z", "gyros_belt_z", "roll_dumbbell", "yaw_forearm", "roll_forearm", "magnet_forearm_y", "gyros_dumbbell_x")]
train2 <- train[,!colnames(train) %in% top20]
fitModel2 <- randomForest(classe ~ ., data=train2,importance=TRUE, ntree=500, mdim2nd=20 , imp=2)
plot(fitModel, log="y")
par(mfrow=c(2,1))
plot(fitModel, log="y"), plot(fitModel2, log="y")
plot(fitModel, log="y"); plot(fitModel2, log="y")
par(mfrow=c(2,1))
plot(fitModel, log="y")
par(mfrow=c(2,1))
par(mar = rep(2, 4))
plot(fitModel, log="y")
plot(fitModel2, log="y")
prediction <- predict(fitModel, train)
cM <- confusionMatrix(prediction, train$classe)
prediction2 <- predict(fitModel2, train)
cM2 <- confusionMatrix(prediction2, train$classe)
diff(cM, cM2)
cM
cM2
fitModel
setwd("D:/RWorking Directory/MachineLearning/MachineLearning/CourseProject")
setwd("D:/RWorking Directory/MachineLearning/MachineLearning/CourseProject")
varImpPlot(fitModel)
top20 <- c("yaw_belt", "roll_belt", "pitch_belt", "magnet_dumbbell_z", "magnet_dumbbell_y",
"gyros_arm_y", "pitch_forearm", "gyros_forearm_z", "roll_arm", "accel_dumbbell_y", "gyros_dumbbell_z","magnet_belt_x", "magnet_forearm_z", "accel_dumbbell_z", "gyros_belt_z", "roll_dumbbell", "yaw_forearm", "roll_forearm", "magnet_forearm_y", "gyros_dumbbell_x")
train2 <- train[,colnames(train) %in% top20]
fitModel2 <- randomForest(classe ~ ., data=train2,importance=TRUE, ntree=500, mdim2nd=20 , imp=2)
par(mfrow=c(2,1))
par(mar = rep(2, 4))
plot(fitModel, log="y")
plot(fitModel2, log="y")
